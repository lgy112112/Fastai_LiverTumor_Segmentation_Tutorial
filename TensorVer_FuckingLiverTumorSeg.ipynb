{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "collapsed_sections": [
        "lHMgAbBnQdeK",
        "znjaU78mnLIh",
        "3huOKgYiBSCI",
        "Gs7TtDj6ljrc"
      ],
      "mount_file_id": "1RhpzKA_OJZbgMqYlDuWGUV454HR8w9At",
      "authorship_tag": "ABX9TyM0D9R95MQt/XFR+IG1GrqO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "cb5288d54d8245ca8230cf9fa0a4e2b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_df76ada952034381a8c513d8e3dc04c2",
              "IPY_MODEL_2b151afc685b4a94b06cadd5ea66cbf9",
              "IPY_MODEL_7f1e93c970b840deba8d19cac6ffab6f"
            ],
            "layout": "IPY_MODEL_7a2c35e9f99c4a27a535caafd2323b9a"
          }
        },
        "df76ada952034381a8c513d8e3dc04c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aab016da8bbe4a3181ea5c82ce784009",
            "placeholder": "​",
            "style": "IPY_MODEL_337c0f1085014c5989073e12f6262974",
            "value": "Epoch 1/5:   0%"
          }
        },
        "2b151afc685b4a94b06cadd5ea66cbf9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_21b1092e8922495eacaf734ed15c21c7",
            "max": 51,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7fa0adc1c8dc48daacc4691b0f5042a5",
            "value": 0
          }
        },
        "7f1e93c970b840deba8d19cac6ffab6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7268519edd6b4bc283b60931b7c68549",
            "placeholder": "​",
            "style": "IPY_MODEL_ad9184bf3b1340dfa9303464c9ffcec7",
            "value": " 0/51 [00:42&lt;?, ?it/s]"
          }
        },
        "7a2c35e9f99c4a27a535caafd2323b9a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aab016da8bbe4a3181ea5c82ce784009": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "337c0f1085014c5989073e12f6262974": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "21b1092e8922495eacaf734ed15c21c7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7fa0adc1c8dc48daacc4691b0f5042a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7268519edd6b4bc283b60931b7c68549": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ad9184bf3b1340dfa9303464c9ffcec7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ede1a600711c4f3bbc930e035249b57e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a1e51b36d1c74521be846fc767b225c7",
              "IPY_MODEL_e32ae78830c84af897138de975d0feff",
              "IPY_MODEL_c428ad2d68574b21830f83db117e7404"
            ],
            "layout": "IPY_MODEL_d7140991e6bf47179fe69b33293975f7"
          }
        },
        "a1e51b36d1c74521be846fc767b225c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9a490486877148258dacc29d4f44d0df",
            "placeholder": "​",
            "style": "IPY_MODEL_b9aebce14ae941328180377d52d08e45",
            "value": "Processing slices:  35%"
          }
        },
        "e32ae78830c84af897138de975d0feff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_656f7065a06b4ea682509f326b4d29db",
            "max": 75,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_631a3cf92b17484c87a2851be36619d3",
            "value": 26
          }
        },
        "c428ad2d68574b21830f83db117e7404": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eafb37e5505f41a8bce62272d5ba0df7",
            "placeholder": "​",
            "style": "IPY_MODEL_ca7bef63244d483f8f324a676a09be5c",
            "value": " 26/75 [00:41&lt;01:14,  1.52s/it, loss=0.00758]"
          }
        },
        "d7140991e6bf47179fe69b33293975f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9a490486877148258dacc29d4f44d0df": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9aebce14ae941328180377d52d08e45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "656f7065a06b4ea682509f326b4d29db": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "631a3cf92b17484c87a2851be36619d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "eafb37e5505f41a8bce62272d5ba0df7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca7bef63244d483f8f324a676a09be5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lgy112112/Fastai_LiverTumor_Segmentation_Tutorial/blob/main/TensorVer_FuckingLiverTumorSeg.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Import😎**"
      ],
      "metadata": {
        "id": "lHMgAbBnQdeK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "import cv2\n",
        "import imageio\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import nibabel as nib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tqdm.notebook import tqdm\n",
        "from ipywidgets import *\n",
        "from PIL import Image\n",
        "from matplotlib.pyplot import figure\n",
        "################################### KEY PACK: FASTAI ###################################\n",
        "from fastai.basics import *\n",
        "from fastai.vision.all import *\n",
        "from fastai.data.transforms import *\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import numpy as np\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "!pip install segmentation_models_pytorch\n",
        "import segmentation_models_pytorch as smp\n",
        "from IPython.display import clear_output\n",
        "from IPython.display import display"
      ],
      "metadata": {
        "id": "dOla49Q0--Pw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "132bf712-ae75-48ba-bc5e-89b940f11af0"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting segmentation_models_pytorch\n",
            "  Downloading segmentation_models_pytorch-0.3.3-py3-none-any.whl (106 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/106.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.7/106.7 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torchvision>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from segmentation_models_pytorch) (0.17.1+cu121)\n",
            "Collecting pretrainedmodels==0.7.4 (from segmentation_models_pytorch)\n",
            "  Downloading pretrainedmodels-0.7.4.tar.gz (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting efficientnet-pytorch==0.7.1 (from segmentation_models_pytorch)\n",
            "  Downloading efficientnet_pytorch-0.7.1.tar.gz (21 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting timm==0.9.2 (from segmentation_models_pytorch)\n",
            "  Downloading timm-0.9.2-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from segmentation_models_pytorch) (4.66.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from segmentation_models_pytorch) (9.4.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (2.2.1+cu121)\n",
            "Collecting munch (from pretrainedmodels==0.7.4->segmentation_models_pytorch)\n",
            "  Downloading munch-4.0.0-py2.py3-none-any.whl (9.9 kB)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from timm==0.9.2->segmentation_models_pytorch) (6.0.1)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from timm==0.9.2->segmentation_models_pytorch) (0.20.3)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from timm==0.9.2->segmentation_models_pytorch) (0.4.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision>=0.5.0->segmentation_models_pytorch) (1.25.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m54.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m58.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m77.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch)\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu12==2.19.3 (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch)\n",
            "  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.99-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m71.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm==0.9.2->segmentation_models_pytorch) (2.31.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm==0.9.2->segmentation_models_pytorch) (24.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm==0.9.2->segmentation_models_pytorch) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm==0.9.2->segmentation_models_pytorch) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm==0.9.2->segmentation_models_pytorch) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm==0.9.2->segmentation_models_pytorch) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (1.3.0)\n",
            "Building wheels for collected packages: efficientnet-pytorch, pretrainedmodels\n",
            "  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for efficientnet-pytorch: filename=efficientnet_pytorch-0.7.1-py3-none-any.whl size=16429 sha256=8a1c678c3ffe23ab8e457790e87eb8c27e4eb16f64ffbaf01c80a0b7cf0c6886\n",
            "  Stored in directory: /root/.cache/pip/wheels/03/3f/e9/911b1bc46869644912bda90a56bcf7b960f20b5187feea3baf\n",
            "  Building wheel for pretrainedmodels (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pretrainedmodels: filename=pretrainedmodels-0.7.4-py3-none-any.whl size=60945 sha256=1f05cf96026af2d5a1d75c32b63ce7be78a8901d76213b92d52d1c876dbce1b6\n",
            "  Stored in directory: /root/.cache/pip/wheels/35/cb/a5/8f534c60142835bfc889f9a482e4a67e0b817032d9c6883b64\n",
            "Successfully built efficientnet-pytorch pretrainedmodels\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, munch, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, efficientnet-pytorch, timm, pretrainedmodels, segmentation_models_pytorch\n",
            "Successfully installed efficientnet-pytorch-0.7.1 munch-4.0.0 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.99 nvidia-nvtx-cu12-12.1.105 pretrainedmodels-0.7.4 segmentation_models_pytorch-0.3.3 timm-0.9.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***DO😡 NOT👿 RUN THIS UNLESS* Introduce raw data from kaggle😶‍🌫️**\n",
        "\n"
      ],
      "metadata": {
        "id": "znjaU78mnLIh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))\n",
        "\n",
        "# Then move kaggle.json into the folder where the API expects to find it.\n",
        "!mkdir -p ~/.kaggle/ && mv kaggle.json ~/.kaggle/ && chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 379
        },
        "id": "0F7flY1XDuZd",
        "outputId": "162354ca-5212-42cc-efcc-f86a12ecfec7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-d9ecffeb-dd5d-4dfc-b172-a81f9ff802fd\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-d9ecffeb-dd5d-4dfc-b172-a81f9ff802fd\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-fa3f74b46278>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0muploaded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0muploaded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mupload\u001b[0;34m()\u001b[0m\n\u001b[1;32m     67\u001b[0m   \"\"\"\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m   \u001b[0muploaded_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_upload_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmultiple\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m   \u001b[0;31m# Mapping from original filename to filename as saved locally.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m   \u001b[0mlocal_filenames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36m_upload_files\u001b[0;34m(multiple)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m   \u001b[0;31m# First result is always an indication that the file picker has completed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m   result = _output.eval_js(\n\u001b[0m\u001b[1;32m    157\u001b[0m       'google.colab._files._uploadFiles(\"{input_id}\", \"{output_id}\")'.format(\n\u001b[1;32m    158\u001b[0m           \u001b[0minput_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/output/_js.py\u001b[0m in \u001b[0;36meval_js\u001b[0;34m(script, ignore_result, timeout_sec)\u001b[0m\n\u001b[1;32m     38\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mignore_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     if (\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gtwjcMR8C5uY"
      },
      "outputs": [],
      "source": [
        "download_path = \"/content/drive/MyDrive/LiTs_Dataset\"\n",
        "\n",
        "# Create the directory if it doesn't exist\n",
        "os.makedirs(download_path, exist_ok=True)\n",
        "\n",
        "# Download the dataset using the Kaggle API\n",
        "kaggle.api.dataset_download_files(\n",
        "    'andrewmvd/liver-tumor-segmentation',\n",
        "    path=download_path,\n",
        "    unzip=True\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Numbering items🥱**"
      ],
      "metadata": {
        "id": "3huOKgYiBSCI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "segmentation_directory = '/content/drive/MyDrive/LiTs_Dataset&Model/segmentations'\n",
        "\n",
        "\n",
        "entries = os.listdir(segmentation_directory)\n",
        "\n",
        "num_entries = len(entries)\n",
        "\n",
        "print(\"Number of entries in the directory:\", num_entries)\n"
      ],
      "metadata": {
        "id": "x2jbs8mGHtOP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ebd9b39-9525-4fed-fcbd-ea980e9efe14"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of entries in the directory: 131\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "volume_directories = ['/content/drive/MyDrive/LiTs_Dataset&Model/volume_pt1',\n",
        "                      '/content/drive/MyDrive/LiTs_Dataset&Model/volume_pt2',\n",
        "                      '/content/drive/MyDrive/LiTs_Dataset&Model/volume_pt3',\n",
        "                      '/content/drive/MyDrive/LiTs_Dataset&Model/volume_pt4',\n",
        "                      '/content/drive/MyDrive/LiTs_Dataset&Model/volume_pt5']\n",
        "\n",
        "total = 0\n",
        "for directory in volume_directories:\n",
        "\n",
        "    entries = os.listdir(directory)\n",
        "\n",
        "    num_entries = len(entries)\n",
        "    total += num_entries\n",
        "    print(f\"Number of entries in {directory}:\", num_entries)\n",
        "print(f\"Sum:\", total)\n"
      ],
      "metadata": {
        "id": "0colypsfMda1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "352e61c2-b3ee-4b9f-9172-a21d182f9798"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of entries in /content/drive/MyDrive/LiTs_Dataset&Model/volume_pt1: 11\n",
            "Number of entries in /content/drive/MyDrive/LiTs_Dataset&Model/volume_pt2: 10\n",
            "Number of entries in /content/drive/MyDrive/LiTs_Dataset&Model/volume_pt3: 10\n",
            "Number of entries in /content/drive/MyDrive/LiTs_Dataset&Model/volume_pt4: 10\n",
            "Number of entries in /content/drive/MyDrive/LiTs_Dataset&Model/volume_pt5: 10\n",
            "Sum: 51\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Sort out index\n",
        "segmentation_list = sorted([os.path.join(segmentation_directory, file) for file in os.listdir(segmentation_directory)], key=lambda x: int(x.split('-')[-1].split('.')[0]))\n",
        "\n",
        "\n",
        "volume_list = []\n",
        "for volume_directory in volume_directories:\n",
        "    volume_files = [os.path.join(volume_directory, file) for file in os.listdir(volume_directory)]\n",
        "    volume_files.sort(key=lambda x: int(x.split('-')[-1].split('.')[0]))\n",
        "    volume_list.extend(volume_files)\n",
        "\n",
        "print(\"Sorted Segmentation List:\")\n",
        "print(segmentation_list)\n",
        "print(\"\\nSorted Volume List:\")\n",
        "print(volume_list)\n"
      ],
      "metadata": {
        "id": "Se3XYWp7NMYB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef2da9b1-6047-48e8-82ef-b2a50e003d39"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sorted Segmentation List:\n",
            "['/content/drive/MyDrive/LiTs_Dataset&Model/segmentations/segmentation-0.nii', '/content/drive/MyDrive/LiTs_Dataset&Model/segmentations/segmentation-1.nii', '/content/drive/MyDrive/LiTs_Dataset&Model/segmentations/segmentation-2.nii', '/content/drive/MyDrive/LiTs_Dataset&Model/segmentations/segmentation-3.nii', '/content/drive/MyDrive/LiTs_Dataset&Model/segmentations/segmentation-4.nii', '/content/drive/MyDrive/LiTs_Dataset&Model/segmentations/segmentation-5.nii', '/content/drive/MyDrive/LiTs_Dataset&Model/segmentations/segmentation-6.nii', '/content/drive/MyDrive/LiTs_Dataset&Model/segmentations/segmentation-7.nii', '/content/drive/MyDrive/LiTs_Dataset&Model/segmentations/segmentation-8.nii', '/content/drive/MyDrive/LiTs_Dataset&Model/segmentations/segmentation-9.nii', '/content/drive/MyDrive/LiTs_Dataset&Model/segmentations/segmentation-10.nii', '/content/drive/MyDrive/LiTs_Dataset&Model/segmentations/segmentation-11.nii', '/content/drive/MyDrive/LiTs_Dataset&Model/segmentations/segmentation-12.nii', '/content/drive/MyDrive/LiTs_Dataset&Model/segmentations/segmentation-13.nii', '/content/drive/MyDrive/LiTs_Dataset&Model/segmentations/segmentation-14.nii', '/content/drive/MyDrive/LiTs_Dataset&Model/segmentations/segmentation-15.nii', '/content/drive/MyDrive/LiTs_Dataset&Model/segmentations/segmentation-16.nii', '/content/drive/MyDrive/LiTs_Dataset&Model/segmentations/segmentation-17.nii', '/content/drive/MyDrive/LiTs_Dataset&Model/segmentations/segmentation-18.nii', '/content/drive/MyDrive/LiTs_Dataset&Model/segmentations/segmentation-19.nii', '/content/drive/MyDrive/LiTs_Dataset&Model/segmentations/segmentation-20.nii', '/content/drive/MyDrive/LiTs_Dataset&Model/segmentations/segmentation-21.nii', '/content/drive/MyDrive/LiTs_Dataset&Model/segmentations/segmentation-22.nii', '/content/drive/MyDrive/LiTs_Dataset&Model/segmentations/segmentation-23.nii', '/content/drive/MyDrive/LiTs_Dataset&Model/segmentations/segmentation-24.nii', '/content/drive/MyDrive/LiTs_Dataset&Model/segmentations/segmentation-25.nii', '/content/drive/MyDrive/LiTs_Dataset&Model/segmentations/segmentation-26.nii', '/content/drive/MyDrive/LiTs_Dataset&Model/segmentations/segmentation-27.nii', '/content/drive/MyDrive/LiTs_Dataset&Model/segmentations/segmentation-28.nii', '/content/drive/MyDrive/LiTs_Dataset&Model/segmentations/segmentation-29.nii', '/content/drive/MyDrive/LiTs_Dataset&Model/segmentations/segmentation-30.nii', '/content/drive/MyDrive/LiTs_Dataset&Model/segmentations/segmentation-31.nii', '/content/drive/MyDrive/LiTs_Dataset&Model/segmentations/segmentation-32.nii', '/content/drive/MyDrive/LiTs_Dataset&Model/segmentations/segmentation-33.nii', '/content/drive/MyDrive/LiTs_Dataset&Model/segmentations/segmentation-34.nii', '/content/drive/MyDrive/LiTs_Dataset&Model/segmentations/segmentation-35.nii', '/content/drive/MyDrive/LiTs_Dataset&Model/segmentations/segmentation-36.nii', '/content/drive/MyDrive/LiTs_Dataset&Model/segmentations/segmentation-37.nii', '/content/drive/MyDrive/LiTs_Dataset&Model/segmentations/segmentation-38.nii', '/content/drive/MyDrive/LiTs_Dataset&Model/segmentations/segmentation-39.nii', '/content/drive/MyDrive/LiTs_Dataset&Model/segmentations/segmentation-40.nii', '/content/drive/MyDrive/LiTs_Dataset&Model/segmentations/segmentation-41.nii', '/content/drive/MyDrive/LiTs_Dataset&Model/segmentations/segmentation-42.nii', '/content/drive/MyDrive/LiTs_Dataset&Model/segmentations/segmentation-43.nii', '/content/drive/MyDrive/LiTs_Dataset&Model/segmentations/segmentation-44.nii', '/content/drive/MyDrive/LiTs_Dataset&Model/segmentations/segmentation-45.nii', '/content/drive/MyDrive/LiTs_Dataset&Model/segmentations/segmentation-46.nii', '/content/drive/MyDrive/LiTs_Dataset&Model/segmentations/segmentation-47.nii', '/content/drive/MyDrive/LiTs_Dataset&Model/segmentations/segmentation-48.nii', '/content/drive/MyDrive/LiTs_Dataset&Model/segmentations/segmentation-49.nii', '/content/drive/MyDrive/LiTs_Dataset&Model/segmentations/segmentation-50.nii', '/content/drive/MyDrive/LiTs_Dataset&Model/segmentations/segmentation-51.nii', '/content/drive/MyDrive/LiTs_Dataset&Model/segmentations/segmentation-52.nii', '/content/drive/MyDrive/LiTs_Dataset&Model/segmentations/segmentation-53.nii', '/content/drive/MyDrive/LiTs_Dataset&Model/segmentations/segmentation-54.nii', '/content/drive/MyDrive/LiTs_Dataset&Model/segmentations/segmentation-55.nii', '/content/drive/MyDrive/LiTs_Dataset&Model/segmentations/segmentation-56.nii', '/content/drive/MyDrive/LiTs_Dataset&Model/segmentations/segmentation-57.nii', '/content/drive/MyDrive/LiTs_Dataset&Model/segmentations/segmentation-58.nii', '/content/drive/MyDrive/LiTs_Dataset&Model/segmentations/segmentation-59.nii', '/content/drive/MyDrive/LiTs_Dataset&Model/segmentations/segmentation-60.nii', '/content/drive/MyDrive/LiTs_Dataset&Model/segmentations/segmentation-61.nii', '/content/drive/MyDrive/LiTs_Dataset&Model/segmentations/segmentation-62.nii', '/content/drive/MyDrive/LiTs_Dataset&Model/segmentations/segmentation-63.nii', '/content/drive/MyDrive/LiTs_Dataset&Model/segmentations/segmentation-64.nii', '/content/drive/MyDrive/LiTs_Dataset&Model/segmentations/segmentation-65.nii', '/content/drive/MyDrive/LiTs_Dataset&Model/segmentations/segmentation-66.nii', '/content/drive/MyDrive/LiTs_Dataset&Model/segmentations/segmentation-67.nii', '/content/drive/MyDrive/LiTs_Dataset&Model/segmentations/segmentation-68.nii', '/content/drive/MyDrive/LiTs_Dataset&Model/segmentations/segmentation-69.nii', '/content/drive/MyDrive/LiTs_Dataset&Model/segmentations/segmentation-70.nii', '/content/drive/MyDrive/LiTs_Dataset&Model/segmentations/segmentation-71.nii', '/content/drive/MyDrive/LiTs_Dataset&Model/segmentations/segmentation-72.nii', '/content/drive/MyDrive/LiTs_Dataset&Model/segmentations/segmentation-73.nii', '/content/drive/MyDrive/LiTs_Dataset&Model/segmentations/segmentation-74.nii', '/content/drive/MyDrive/LiTs_Dataset&Model/segmentations/segmentation-75.nii', '/content/drive/MyDrive/LiTs_Dataset&Model/segmentations/segmentation-76.nii', '/content/drive/MyDrive/LiTs_Dataset&Model/segmentations/segmentation-77.nii', '/content/drive/MyDrive/LiTs_Dataset&Model/segmentations/segmentation-78.nii', '/content/drive/MyDrive/LiTs_Dataset&Model/segmentations/segmentation-79.nii', '/content/drive/MyDrive/LiTs_Dataset&Model/segmentations/segmentation-80.nii', '/content/drive/MyDrive/LiTs_Dataset&Model/segmentations/segmentation-81.nii', '/content/drive/MyDrive/LiTs_Dataset&Model/segmentations/segmentation-82.nii', '/content/drive/MyDrive/LiTs_Dataset&Model/segmentations/segmentation-83.nii', '/content/drive/MyDrive/LiTs_Dataset&Model/segmentations/segmentation-84.nii', '/content/drive/MyDrive/LiTs_Dataset&Model/segmentations/segmentation-85.nii', '/content/drive/MyDrive/LiTs_Dataset&Model/segmentations/segmentation-86.nii', '/content/drive/MyDrive/LiTs_Dataset&Model/segmentations/segmentation-87.nii', '/content/drive/MyDrive/LiTs_Dataset&Model/segmentations/segmentation-88.nii', '/content/drive/MyDrive/LiTs_Dataset&Model/segmentations/segmentation-89.nii', '/content/drive/MyDrive/LiTs_Dataset&Model/segmentations/segmentation-90.nii', '/content/drive/MyDrive/LiTs_Dataset&Model/segmentations/segmentation-91.nii', '/content/drive/MyDrive/LiTs_Dataset&Model/segmentations/segmentation-92.nii', '/content/drive/MyDrive/LiTs_Dataset&Model/segmentations/segmentation-93.nii', '/content/drive/MyDrive/LiTs_Dataset&Model/segmentations/segmentation-94.nii', '/content/drive/MyDrive/LiTs_Dataset&Model/segmentations/segmentation-95.nii', '/content/drive/MyDrive/LiTs_Dataset&Model/segmentations/segmentation-96.nii', '/content/drive/MyDrive/LiTs_Dataset&Model/segmentations/segmentation-97.nii', '/content/drive/MyDrive/LiTs_Dataset&Model/segmentations/segmentation-98.nii', '/content/drive/MyDrive/LiTs_Dataset&Model/segmentations/segmentation-99.nii', '/content/drive/MyDrive/LiTs_Dataset&Model/segmentations/segmentation-100.nii', '/content/drive/MyDrive/LiTs_Dataset&Model/segmentations/segmentation-101.nii', '/content/drive/MyDrive/LiTs_Dataset&Model/segmentations/segmentation-102.nii', '/content/drive/MyDrive/LiTs_Dataset&Model/segmentations/segmentation-103.nii', '/content/drive/MyDrive/LiTs_Dataset&Model/segmentations/segmentation-104.nii', '/content/drive/MyDrive/LiTs_Dataset&Model/segmentations/segmentation-105.nii', '/content/drive/MyDrive/LiTs_Dataset&Model/segmentations/segmentation-106.nii', '/content/drive/MyDrive/LiTs_Dataset&Model/segmentations/segmentation-107.nii', '/content/drive/MyDrive/LiTs_Dataset&Model/segmentations/segmentation-108.nii', '/content/drive/MyDrive/LiTs_Dataset&Model/segmentations/segmentation-109.nii', '/content/drive/MyDrive/LiTs_Dataset&Model/segmentations/segmentation-110.nii', '/content/drive/MyDrive/LiTs_Dataset&Model/segmentations/segmentation-111.nii', '/content/drive/MyDrive/LiTs_Dataset&Model/segmentations/segmentation-112.nii', '/content/drive/MyDrive/LiTs_Dataset&Model/segmentations/segmentation-113.nii', '/content/drive/MyDrive/LiTs_Dataset&Model/segmentations/segmentation-114.nii', '/content/drive/MyDrive/LiTs_Dataset&Model/segmentations/segmentation-115.nii', '/content/drive/MyDrive/LiTs_Dataset&Model/segmentations/segmentation-116.nii', '/content/drive/MyDrive/LiTs_Dataset&Model/segmentations/segmentation-117.nii', '/content/drive/MyDrive/LiTs_Dataset&Model/segmentations/segmentation-118.nii', '/content/drive/MyDrive/LiTs_Dataset&Model/segmentations/segmentation-119.nii', '/content/drive/MyDrive/LiTs_Dataset&Model/segmentations/segmentation-120.nii', '/content/drive/MyDrive/LiTs_Dataset&Model/segmentations/segmentation-121.nii', '/content/drive/MyDrive/LiTs_Dataset&Model/segmentations/segmentation-122.nii', '/content/drive/MyDrive/LiTs_Dataset&Model/segmentations/segmentation-123.nii', '/content/drive/MyDrive/LiTs_Dataset&Model/segmentations/segmentation-124.nii', '/content/drive/MyDrive/LiTs_Dataset&Model/segmentations/segmentation-125.nii', '/content/drive/MyDrive/LiTs_Dataset&Model/segmentations/segmentation-126.nii', '/content/drive/MyDrive/LiTs_Dataset&Model/segmentations/segmentation-127.nii', '/content/drive/MyDrive/LiTs_Dataset&Model/segmentations/segmentation-128.nii', '/content/drive/MyDrive/LiTs_Dataset&Model/segmentations/segmentation-129.nii', '/content/drive/MyDrive/LiTs_Dataset&Model/segmentations/segmentation-130.nii']\n",
            "\n",
            "Sorted Volume List:\n",
            "['/content/drive/MyDrive/LiTs_Dataset&Model/volume_pt1/volume-0.nii', '/content/drive/MyDrive/LiTs_Dataset&Model/volume_pt1/volume-1.nii', '/content/drive/MyDrive/LiTs_Dataset&Model/volume_pt1/volume-2.nii', '/content/drive/MyDrive/LiTs_Dataset&Model/volume_pt1/volume-3.nii', '/content/drive/MyDrive/LiTs_Dataset&Model/volume_pt1/volume-4.nii', '/content/drive/MyDrive/LiTs_Dataset&Model/volume_pt1/volume-5.nii', '/content/drive/MyDrive/LiTs_Dataset&Model/volume_pt1/volume-6.nii', '/content/drive/MyDrive/LiTs_Dataset&Model/volume_pt1/volume-7.nii', '/content/drive/MyDrive/LiTs_Dataset&Model/volume_pt1/volume-8.nii', '/content/drive/MyDrive/LiTs_Dataset&Model/volume_pt1/volume-9.nii', '/content/drive/MyDrive/LiTs_Dataset&Model/volume_pt1/volume-10.nii', '/content/drive/MyDrive/LiTs_Dataset&Model/volume_pt2/volume-11.nii', '/content/drive/MyDrive/LiTs_Dataset&Model/volume_pt2/volume-12.nii', '/content/drive/MyDrive/LiTs_Dataset&Model/volume_pt2/volume-13.nii', '/content/drive/MyDrive/LiTs_Dataset&Model/volume_pt2/volume-14.nii', '/content/drive/MyDrive/LiTs_Dataset&Model/volume_pt2/volume-15.nii', '/content/drive/MyDrive/LiTs_Dataset&Model/volume_pt2/volume-16.nii', '/content/drive/MyDrive/LiTs_Dataset&Model/volume_pt2/volume-17.nii', '/content/drive/MyDrive/LiTs_Dataset&Model/volume_pt2/volume-18.nii', '/content/drive/MyDrive/LiTs_Dataset&Model/volume_pt2/volume-19.nii', '/content/drive/MyDrive/LiTs_Dataset&Model/volume_pt2/volume-20.nii', '/content/drive/MyDrive/LiTs_Dataset&Model/volume_pt3/volume-21.nii', '/content/drive/MyDrive/LiTs_Dataset&Model/volume_pt3/volume-22.nii', '/content/drive/MyDrive/LiTs_Dataset&Model/volume_pt3/volume-23.nii', '/content/drive/MyDrive/LiTs_Dataset&Model/volume_pt3/volume-24.nii', '/content/drive/MyDrive/LiTs_Dataset&Model/volume_pt3/volume-25.nii', '/content/drive/MyDrive/LiTs_Dataset&Model/volume_pt3/volume-26.nii', '/content/drive/MyDrive/LiTs_Dataset&Model/volume_pt3/volume-27.nii', '/content/drive/MyDrive/LiTs_Dataset&Model/volume_pt3/volume-28.nii', '/content/drive/MyDrive/LiTs_Dataset&Model/volume_pt3/volume-29.nii', '/content/drive/MyDrive/LiTs_Dataset&Model/volume_pt3/volume-30.nii', '/content/drive/MyDrive/LiTs_Dataset&Model/volume_pt4/volume-31.nii', '/content/drive/MyDrive/LiTs_Dataset&Model/volume_pt4/volume-32.nii', '/content/drive/MyDrive/LiTs_Dataset&Model/volume_pt4/volume-33.nii', '/content/drive/MyDrive/LiTs_Dataset&Model/volume_pt4/volume-34.nii', '/content/drive/MyDrive/LiTs_Dataset&Model/volume_pt4/volume-35.nii', '/content/drive/MyDrive/LiTs_Dataset&Model/volume_pt4/volume-36.nii', '/content/drive/MyDrive/LiTs_Dataset&Model/volume_pt4/volume-37.nii', '/content/drive/MyDrive/LiTs_Dataset&Model/volume_pt4/volume-38.nii', '/content/drive/MyDrive/LiTs_Dataset&Model/volume_pt4/volume-39.nii', '/content/drive/MyDrive/LiTs_Dataset&Model/volume_pt4/volume-40.nii', '/content/drive/MyDrive/LiTs_Dataset&Model/volume_pt5/volume-41.nii', '/content/drive/MyDrive/LiTs_Dataset&Model/volume_pt5/volume-42.nii', '/content/drive/MyDrive/LiTs_Dataset&Model/volume_pt5/volume-43.nii', '/content/drive/MyDrive/LiTs_Dataset&Model/volume_pt5/volume-44.nii', '/content/drive/MyDrive/LiTs_Dataset&Model/volume_pt5/volume-45.nii', '/content/drive/MyDrive/LiTs_Dataset&Model/volume_pt5/volume-46.nii', '/content/drive/MyDrive/LiTs_Dataset&Model/volume_pt5/volume-47.nii', '/content/drive/MyDrive/LiTs_Dataset&Model/volume_pt5/volume-48.nii', '/content/drive/MyDrive/LiTs_Dataset&Model/volume_pt5/volume-49.nii', '/content/drive/MyDrive/LiTs_Dataset&Model/volume_pt5/volume-50.nii']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "segmentation_list = segmentation_list[0:51]"
      ],
      "metadata": {
        "id": "B4VlIGFfO1WK"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "segmentation_list, volume_list"
      ],
      "metadata": {
        "id": "b6NsAFn2QJTn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "faa06107-1de6-41e2-9c59-9ab9940d541b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['/content/drive/MyDrive/LiTs_Dataset&Model/segmentations/segmentation-0.nii',\n",
              "  '/content/drive/MyDrive/LiTs_Dataset&Model/segmentations/segmentation-1.nii',\n",
              "  '/content/drive/MyDrive/LiTs_Dataset&Model/segmentations/segmentation-2.nii',\n",
              "  '/content/drive/MyDrive/LiTs_Dataset&Model/segmentations/segmentation-3.nii',\n",
              "  '/content/drive/MyDrive/LiTs_Dataset&Model/segmentations/segmentation-4.nii',\n",
              "  '/content/drive/MyDrive/LiTs_Dataset&Model/segmentations/segmentation-5.nii',\n",
              "  '/content/drive/MyDrive/LiTs_Dataset&Model/segmentations/segmentation-6.nii',\n",
              "  '/content/drive/MyDrive/LiTs_Dataset&Model/segmentations/segmentation-7.nii',\n",
              "  '/content/drive/MyDrive/LiTs_Dataset&Model/segmentations/segmentation-8.nii',\n",
              "  '/content/drive/MyDrive/LiTs_Dataset&Model/segmentations/segmentation-9.nii',\n",
              "  '/content/drive/MyDrive/LiTs_Dataset&Model/segmentations/segmentation-10.nii',\n",
              "  '/content/drive/MyDrive/LiTs_Dataset&Model/segmentations/segmentation-11.nii',\n",
              "  '/content/drive/MyDrive/LiTs_Dataset&Model/segmentations/segmentation-12.nii',\n",
              "  '/content/drive/MyDrive/LiTs_Dataset&Model/segmentations/segmentation-13.nii',\n",
              "  '/content/drive/MyDrive/LiTs_Dataset&Model/segmentations/segmentation-14.nii',\n",
              "  '/content/drive/MyDrive/LiTs_Dataset&Model/segmentations/segmentation-15.nii',\n",
              "  '/content/drive/MyDrive/LiTs_Dataset&Model/segmentations/segmentation-16.nii',\n",
              "  '/content/drive/MyDrive/LiTs_Dataset&Model/segmentations/segmentation-17.nii',\n",
              "  '/content/drive/MyDrive/LiTs_Dataset&Model/segmentations/segmentation-18.nii',\n",
              "  '/content/drive/MyDrive/LiTs_Dataset&Model/segmentations/segmentation-19.nii',\n",
              "  '/content/drive/MyDrive/LiTs_Dataset&Model/segmentations/segmentation-20.nii',\n",
              "  '/content/drive/MyDrive/LiTs_Dataset&Model/segmentations/segmentation-21.nii',\n",
              "  '/content/drive/MyDrive/LiTs_Dataset&Model/segmentations/segmentation-22.nii',\n",
              "  '/content/drive/MyDrive/LiTs_Dataset&Model/segmentations/segmentation-23.nii',\n",
              "  '/content/drive/MyDrive/LiTs_Dataset&Model/segmentations/segmentation-24.nii',\n",
              "  '/content/drive/MyDrive/LiTs_Dataset&Model/segmentations/segmentation-25.nii',\n",
              "  '/content/drive/MyDrive/LiTs_Dataset&Model/segmentations/segmentation-26.nii',\n",
              "  '/content/drive/MyDrive/LiTs_Dataset&Model/segmentations/segmentation-27.nii',\n",
              "  '/content/drive/MyDrive/LiTs_Dataset&Model/segmentations/segmentation-28.nii',\n",
              "  '/content/drive/MyDrive/LiTs_Dataset&Model/segmentations/segmentation-29.nii',\n",
              "  '/content/drive/MyDrive/LiTs_Dataset&Model/segmentations/segmentation-30.nii',\n",
              "  '/content/drive/MyDrive/LiTs_Dataset&Model/segmentations/segmentation-31.nii',\n",
              "  '/content/drive/MyDrive/LiTs_Dataset&Model/segmentations/segmentation-32.nii',\n",
              "  '/content/drive/MyDrive/LiTs_Dataset&Model/segmentations/segmentation-33.nii',\n",
              "  '/content/drive/MyDrive/LiTs_Dataset&Model/segmentations/segmentation-34.nii',\n",
              "  '/content/drive/MyDrive/LiTs_Dataset&Model/segmentations/segmentation-35.nii',\n",
              "  '/content/drive/MyDrive/LiTs_Dataset&Model/segmentations/segmentation-36.nii',\n",
              "  '/content/drive/MyDrive/LiTs_Dataset&Model/segmentations/segmentation-37.nii',\n",
              "  '/content/drive/MyDrive/LiTs_Dataset&Model/segmentations/segmentation-38.nii',\n",
              "  '/content/drive/MyDrive/LiTs_Dataset&Model/segmentations/segmentation-39.nii',\n",
              "  '/content/drive/MyDrive/LiTs_Dataset&Model/segmentations/segmentation-40.nii',\n",
              "  '/content/drive/MyDrive/LiTs_Dataset&Model/segmentations/segmentation-41.nii',\n",
              "  '/content/drive/MyDrive/LiTs_Dataset&Model/segmentations/segmentation-42.nii',\n",
              "  '/content/drive/MyDrive/LiTs_Dataset&Model/segmentations/segmentation-43.nii',\n",
              "  '/content/drive/MyDrive/LiTs_Dataset&Model/segmentations/segmentation-44.nii',\n",
              "  '/content/drive/MyDrive/LiTs_Dataset&Model/segmentations/segmentation-45.nii',\n",
              "  '/content/drive/MyDrive/LiTs_Dataset&Model/segmentations/segmentation-46.nii',\n",
              "  '/content/drive/MyDrive/LiTs_Dataset&Model/segmentations/segmentation-47.nii',\n",
              "  '/content/drive/MyDrive/LiTs_Dataset&Model/segmentations/segmentation-48.nii',\n",
              "  '/content/drive/MyDrive/LiTs_Dataset&Model/segmentations/segmentation-49.nii',\n",
              "  '/content/drive/MyDrive/LiTs_Dataset&Model/segmentations/segmentation-50.nii'],\n",
              " ['/content/drive/MyDrive/LiTs_Dataset&Model/volume_pt1/volume-0.nii',\n",
              "  '/content/drive/MyDrive/LiTs_Dataset&Model/volume_pt1/volume-1.nii',\n",
              "  '/content/drive/MyDrive/LiTs_Dataset&Model/volume_pt1/volume-2.nii',\n",
              "  '/content/drive/MyDrive/LiTs_Dataset&Model/volume_pt1/volume-3.nii',\n",
              "  '/content/drive/MyDrive/LiTs_Dataset&Model/volume_pt1/volume-4.nii',\n",
              "  '/content/drive/MyDrive/LiTs_Dataset&Model/volume_pt1/volume-5.nii',\n",
              "  '/content/drive/MyDrive/LiTs_Dataset&Model/volume_pt1/volume-6.nii',\n",
              "  '/content/drive/MyDrive/LiTs_Dataset&Model/volume_pt1/volume-7.nii',\n",
              "  '/content/drive/MyDrive/LiTs_Dataset&Model/volume_pt1/volume-8.nii',\n",
              "  '/content/drive/MyDrive/LiTs_Dataset&Model/volume_pt1/volume-9.nii',\n",
              "  '/content/drive/MyDrive/LiTs_Dataset&Model/volume_pt1/volume-10.nii',\n",
              "  '/content/drive/MyDrive/LiTs_Dataset&Model/volume_pt2/volume-11.nii',\n",
              "  '/content/drive/MyDrive/LiTs_Dataset&Model/volume_pt2/volume-12.nii',\n",
              "  '/content/drive/MyDrive/LiTs_Dataset&Model/volume_pt2/volume-13.nii',\n",
              "  '/content/drive/MyDrive/LiTs_Dataset&Model/volume_pt2/volume-14.nii',\n",
              "  '/content/drive/MyDrive/LiTs_Dataset&Model/volume_pt2/volume-15.nii',\n",
              "  '/content/drive/MyDrive/LiTs_Dataset&Model/volume_pt2/volume-16.nii',\n",
              "  '/content/drive/MyDrive/LiTs_Dataset&Model/volume_pt2/volume-17.nii',\n",
              "  '/content/drive/MyDrive/LiTs_Dataset&Model/volume_pt2/volume-18.nii',\n",
              "  '/content/drive/MyDrive/LiTs_Dataset&Model/volume_pt2/volume-19.nii',\n",
              "  '/content/drive/MyDrive/LiTs_Dataset&Model/volume_pt2/volume-20.nii',\n",
              "  '/content/drive/MyDrive/LiTs_Dataset&Model/volume_pt3/volume-21.nii',\n",
              "  '/content/drive/MyDrive/LiTs_Dataset&Model/volume_pt3/volume-22.nii',\n",
              "  '/content/drive/MyDrive/LiTs_Dataset&Model/volume_pt3/volume-23.nii',\n",
              "  '/content/drive/MyDrive/LiTs_Dataset&Model/volume_pt3/volume-24.nii',\n",
              "  '/content/drive/MyDrive/LiTs_Dataset&Model/volume_pt3/volume-25.nii',\n",
              "  '/content/drive/MyDrive/LiTs_Dataset&Model/volume_pt3/volume-26.nii',\n",
              "  '/content/drive/MyDrive/LiTs_Dataset&Model/volume_pt3/volume-27.nii',\n",
              "  '/content/drive/MyDrive/LiTs_Dataset&Model/volume_pt3/volume-28.nii',\n",
              "  '/content/drive/MyDrive/LiTs_Dataset&Model/volume_pt3/volume-29.nii',\n",
              "  '/content/drive/MyDrive/LiTs_Dataset&Model/volume_pt3/volume-30.nii',\n",
              "  '/content/drive/MyDrive/LiTs_Dataset&Model/volume_pt4/volume-31.nii',\n",
              "  '/content/drive/MyDrive/LiTs_Dataset&Model/volume_pt4/volume-32.nii',\n",
              "  '/content/drive/MyDrive/LiTs_Dataset&Model/volume_pt4/volume-33.nii',\n",
              "  '/content/drive/MyDrive/LiTs_Dataset&Model/volume_pt4/volume-34.nii',\n",
              "  '/content/drive/MyDrive/LiTs_Dataset&Model/volume_pt4/volume-35.nii',\n",
              "  '/content/drive/MyDrive/LiTs_Dataset&Model/volume_pt4/volume-36.nii',\n",
              "  '/content/drive/MyDrive/LiTs_Dataset&Model/volume_pt4/volume-37.nii',\n",
              "  '/content/drive/MyDrive/LiTs_Dataset&Model/volume_pt4/volume-38.nii',\n",
              "  '/content/drive/MyDrive/LiTs_Dataset&Model/volume_pt4/volume-39.nii',\n",
              "  '/content/drive/MyDrive/LiTs_Dataset&Model/volume_pt4/volume-40.nii',\n",
              "  '/content/drive/MyDrive/LiTs_Dataset&Model/volume_pt5/volume-41.nii',\n",
              "  '/content/drive/MyDrive/LiTs_Dataset&Model/volume_pt5/volume-42.nii',\n",
              "  '/content/drive/MyDrive/LiTs_Dataset&Model/volume_pt5/volume-43.nii',\n",
              "  '/content/drive/MyDrive/LiTs_Dataset&Model/volume_pt5/volume-44.nii',\n",
              "  '/content/drive/MyDrive/LiTs_Dataset&Model/volume_pt5/volume-45.nii',\n",
              "  '/content/drive/MyDrive/LiTs_Dataset&Model/volume_pt5/volume-46.nii',\n",
              "  '/content/drive/MyDrive/LiTs_Dataset&Model/volume_pt5/volume-47.nii',\n",
              "  '/content/drive/MyDrive/LiTs_Dataset&Model/volume_pt5/volume-48.nii',\n",
              "  '/content/drive/MyDrive/LiTs_Dataset&Model/volume_pt5/volume-49.nii',\n",
              "  '/content/drive/MyDrive/LiTs_Dataset&Model/volume_pt5/volume-50.nii'])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **After item, view data with *2 lists*😊**\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "M_GlKAnLC4WW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a_list = volume_list\n",
        "b_list = segmentation_list\n",
        "len(a_list), len(b_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1x30CbpEgz5z",
        "outputId": "b3599146-1403-4707-bfda-9f85f24fe617"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(51, 51)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nibabel as nib\n",
        "import numpy as np\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "import types\n",
        "\n",
        "dicom_windows = types.SimpleNamespace( # some tuples to store\n",
        "    brain=(80,40),\n",
        "    subdural=(254,100),\n",
        "    stroke=(8,32),\n",
        "    brain_bone=(2800,600),\n",
        "    brain_soft=(375,40),\n",
        "    lungs=(1500,-600),\n",
        "    mediastinum=(350,50),\n",
        "    abdomen_soft=(400,50),\n",
        "    liver=(300,0),\n",
        "    spine_soft=(250,50),\n",
        "    spine_bone=(1800,400),\n",
        "    custom = (200,60)\n",
        ")\n",
        "\n",
        "@patch\n",
        "def windowed(self:Tensor, w, l):\n",
        "    px = self.clone()\n",
        "    px_min = l - w//2\n",
        "    px_max = l + w//2\n",
        "    px[px<px_min] = px_min\n",
        "    px[px>px_max] = px_max\n",
        "    return (px-px_min) / (px_max-px_min) #Normalization\n",
        "\n",
        "# 定义一个函数来加载数据，转换为张量，并应用窗宽和one-hot编码\n",
        "def load_and_process_data(volume_path, mask_path):\n",
        "    \"\"\"\n",
        "    加载一对体积和掩膜数据，转换为张量，应用窗宽和one-hot编码\n",
        "    :param volume_path: 体积数据的路径\n",
        "    :param mask_path: 掩膜数据的路径\n",
        "    :param window_name: 使用的窗宽名称\n",
        "    :return: 处理后的体积和掩膜数据张量\n",
        "    \"\"\"\n",
        "    # 使用内存映射加载 nii 文件\n",
        "    volume_nii = nib.load(volume_path, mmap=True)\n",
        "    mask_nii = nib.load(mask_path, mmap=True)\n",
        "\n",
        "    # 获取数据数组，并转换为张量\n",
        "    volume_tensor = (torch.from_numpy(np.asanyarray(volume_nii.dataobj).astype(np.float32))).windowed(*dicom_windows.liver)\n",
        "    mask_tensor = torch.from_numpy(np.asanyarray(mask_nii.dataobj).astype(np.int64))\n",
        "\n",
        "\n",
        "    # 对掩膜数据进行one-hot编码\n",
        "    mask_tensor = torch.nn.functional.one_hot(mask_tensor, num_classes=3).permute(3, 0, 1, 2).to(torch.float32)\n",
        "\n",
        "    return volume_tensor, mask_tensor\n",
        "\n",
        "\n",
        "def print_info_and_show_image(volume, mask):\n",
        "    # 打印形状、最大值和最小值\n",
        "    print(\"Volume Shape:\", volume.shape)\n",
        "    print(\"Volume Max Value:\", volume.max().item())\n",
        "    print(\"Volume Min Value:\", volume.min().item())\n",
        "    print(\"Mask Shape:\", mask.shape)\n",
        "    print(\"Mask Max Value:\", mask.max().item())\n",
        "    print(\"Mask Min Value:\", mask.min().item())\n",
        "\n",
        "    # 显示体积和掩膜的一个中间切片图像\n",
        "    fig, axes = plt.subplots(1, 4, figsize=(20, 5), dpi=120)  # 调整为4个子图\n",
        "    slice_idx = 56  # 选择中间的切片\n",
        "\n",
        "    # 显示体积切片\n",
        "    axes[0].imshow(volume[:, :, slice_idx])\n",
        "    axes[0].set_title('Volume Slice')\n",
        "\n",
        "    # 显示掩膜的每个通道对应的切片\n",
        "    for i in range(3):\n",
        "        # 注意：掩膜数据格式为 (C, H, W, D)，其中 C 是通道数\n",
        "        axes[i+1].imshow(mask[i, :, :, slice_idx])\n",
        "        axes[i+1].set_title(f'Mask Channel {i} Slice')\n",
        "\n",
        "    # 显示图像\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def plot_metrics(metrics, title='Training Metrics'):\n",
        "    # 这里我们创建一个新的图形对象而不清除之前的输出\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    for label, metric in metrics.items():\n",
        "        plt.plot(metric, label=label)\n",
        "    plt.title(title)\n",
        "    plt.xlabel('Batch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def visualize_slice(volume_slice, true_mask, predicted_output):\n",
        "    fig, axes = plt.subplots(2, 4, figsize=(20, 10))  # 2行4列的子图布局\n",
        "\n",
        "    # 显示体积切片\n",
        "    vol = volume_slice.cpu().squeeze()\n",
        "    axes[0, 0].imshow(vol, cmap='bone')\n",
        "    axes[0, 0].set_title('Volume Slice')\n",
        "\n",
        "    # 显示每个类别的真实掩码\n",
        "    if true_mask.shape[1] == 3:  # 确保有3个类别\n",
        "        for i in range(3):\n",
        "            axes[0, i+1].imshow(true_mask[0, i].cpu().squeeze(), cmap='bone')  # 直接显示\n",
        "            axes[0, i+1].set_title(f'True Mask Class {i}')\n",
        "\n",
        "    # 显示通过argmax得到的预测掩码\n",
        "    predicted_class = torch.argmax(predicted_output, dim=1).cpu().squeeze()  # 使用argmax获取预测类别\n",
        "    axes[1, 0].imshow(predicted_class, cmap='bone')  # 显示预测掩码\n",
        "    axes[1, 0].set_title('Predicted Mask by Argmax')\n",
        "\n",
        "    # 显示预测的每个类别概率图\n",
        "    for i in range(3):\n",
        "        # Softmax 转换为概率分布\n",
        "        prob_maps = torch.softmax(predicted_output, dim=1)[0, i].cpu().squeeze()\n",
        "        axes[1, i+1].imshow(prob_maps, cmap='bone')  # 使用概率分布进行可视化\n",
        "        axes[1, i+1].set_title(f'Predicted Prob Class {i}')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def predict_and_visualize(model, volume_slice, mask_slice): # # torch.Size([1, 1, 512, 512]) torch.Size([1, 3, 512, 512])\n",
        "    with torch.no_grad():\n",
        "        model.eval()  # Set model to evaluation mode\n",
        "        # print(f'volume_slice shape: {volume_slice.shape}') # volume_slice shape: torch.Size([1, 1, 512, 512])\n",
        "        # print(f'mask_slice shape: {mask_slice.shape}') # mask_slice shape: torch.Size([1, 3, 512, 512])\n",
        "\n",
        "        predicted_output = model(volume_slice)\n",
        "        # print(f'predicted_output shape: {predicted_output.shape}') # predicted_output shape: torch.Size([1, 3, 512, 512])\n",
        "\n",
        "\n",
        "        # predicted_mask = torch.argmax(predicted_output, dim=1) # predicted_mask shape: torch.Size([1, 512, 512])\n",
        "        # print(f'predicted_mask shape: {predicted_mask.shape}')\n",
        "\n",
        "        visualize_slice(volume_slice, mask_slice, predicted_output)\n",
        "    model.train()  # Set model back to train mode\n"
      ],
      "metadata": {
        "id": "bQgp4qaIQyWK"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test_volume, test_mask = load_and_process_data(volume_list[0], segmentation_list[0])\n",
        "# test_volume.shape, test_mask.shape\n",
        "\n",
        "# print_info_and_show_image(test_volume, test_mask)\n",
        "# del test_volume, test_mask"
      ],
      "metadata": {
        "id": "FRXA9uuNqjTD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import nibabel as nib\n",
        "import numpy as np\n",
        "\n",
        "class NIfTIDataset(Dataset):\n",
        "    def __init__(self, volume_paths, mask_paths):\n",
        "        \"\"\"\n",
        "        初始化数据集。\n",
        "        :param volume_paths: 体积数据的路径列表。\n",
        "        :param mask_paths: 掩膜数据的路径列表。\n",
        "        :param window_name: 使用的窗宽名称。\n",
        "        \"\"\"\n",
        "        self.volume_paths = volume_paths\n",
        "        self.mask_paths = mask_paths\n",
        "        # self.window_name = window_name\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"\n",
        "        返回数据集中的样本数。\n",
        "        \"\"\"\n",
        "        return len(self.volume_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\"\n",
        "        根据索引加载并返回一个样本。\n",
        "        \"\"\"\n",
        "        volume_path = self.volume_paths[idx]\n",
        "        mask_path = self.mask_paths[idx]\n",
        "        volume_slices, mask_slices = load_and_process_data(volume_path, mask_path)\n",
        "\n",
        "        return volume_slices, mask_slices\n",
        "\n",
        "\n",
        "dataset = NIfTIDataset(a_list, b_list)\n",
        "\n",
        "# DataLoader\n",
        "data_loader = DataLoader(dataset, batch_size=1, shuffle=False, num_workers=0)\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "# 定义模型，假设我们正在处理三个类别的分割：背景、肝脏、肿瘤\n",
        "model = smp.Unet(encoder_name=\"resnet34\", encoder_weights=\"imagenet\", in_channels=1, classes=3).to(device)\n",
        "\n",
        "# 定义损失函数和优化器\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "num_epochs = 5  # 假定训练5个epoch"
      ],
      "metadata": {
        "id": "FfQzRqgjv0Of"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display\n",
        "from tqdm.notebook import tqdm\n",
        "import gc\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    total_loss = 0.0\n",
        "    with tqdm(enumerate(data_loader), total=len(data_loader), desc=f'Epoch {epoch+1}/{num_epochs}', leave=True) as outer_tqdm:\n",
        "        for batch_idx, (volume_slices, mask_slices) in outer_tqdm: # torch.Size([1, 1, 512, 512, D]) torch.Size([1, 3, 512, 512, D])\n",
        "            D = volume_slices.shape[-1]\n",
        "            with tqdm(range(D), desc='Processing slices', leave=False) as inner_tqdm:\n",
        "                for d in inner_tqdm:\n",
        "                    volume_slice = volume_slices[:, :, :, d].unsqueeze(1).to(device) # torch.Size([1, 1, 512, 512])\n",
        "                    mask_slice = mask_slices[:, :, :, :, d].to(device) # torch.Size([1, 3, 512, 512])\n",
        "\n",
        "                    # print(volume_slice.shape, mask_slice.shape)\n",
        "                    # break\n",
        "\n",
        "                    optimizer.zero_grad()\n",
        "                    outputs = model(volume_slice)\n",
        "                    print(f'outputs shape: {outputs.shape}')\n",
        "                    mask_slice_argmax = torch.argmax(mask_slice, 1)\n",
        "                    print(f'mask_slice_argmax shape: {mask_slice_argmax.shape}')\n",
        "                    # print mask_slice_argmax unique value\n",
        "                    print(f'mask_slice_argmax unique value: {torch.unique(mask_slice_argmax)}')\n",
        "\n",
        "                    loss = criterion(outputs, mask_slice_argmax.long())\n",
        "                    loss.backward()\n",
        "                    optimizer.step()\n",
        "\n",
        "                    total_loss += loss.item()\n",
        "                    inner_tqdm.set_postfix(loss=loss.item())\n",
        "                    del volume_slice, mask_slice\n",
        "                    gc.collect()\n",
        "\n",
        "            # Predict and visualize after processing all slices of the current batch\n",
        "            # Here we randomly select one slice to predict and visualize\n",
        "            random_d = random.randint(0, D-1)\n",
        "            predict_and_visualize(model, volume_slices[:, :, :, random_d].unsqueeze(1).to(device), mask_slices[:, :, :, :, random_d].to(device))\n",
        "                          # torch.Size([1, 1, 512, 512]) torch.Size([1, 3, 512, 512])\n",
        "\n",
        "            avg_loss = total_loss / ((batch_idx + 1) * D)\n",
        "            outer_tqdm.set_postfix(avg_loss=avg_loss)\n",
        "\n",
        "    plot_metrics({'Training Loss': [total_loss / ((batch_idx + 1) * D)]}, title=f'Epoch {epoch+1}/{num_epochs} - Training Loss')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "cb5288d54d8245ca8230cf9fa0a4e2b3",
            "df76ada952034381a8c513d8e3dc04c2",
            "2b151afc685b4a94b06cadd5ea66cbf9",
            "7f1e93c970b840deba8d19cac6ffab6f",
            "7a2c35e9f99c4a27a535caafd2323b9a",
            "aab016da8bbe4a3181ea5c82ce784009",
            "337c0f1085014c5989073e12f6262974",
            "21b1092e8922495eacaf734ed15c21c7",
            "7fa0adc1c8dc48daacc4691b0f5042a5",
            "7268519edd6b4bc283b60931b7c68549",
            "ad9184bf3b1340dfa9303464c9ffcec7",
            "ede1a600711c4f3bbc930e035249b57e",
            "a1e51b36d1c74521be846fc767b225c7",
            "e32ae78830c84af897138de975d0feff",
            "c428ad2d68574b21830f83db117e7404",
            "d7140991e6bf47179fe69b33293975f7",
            "9a490486877148258dacc29d4f44d0df",
            "b9aebce14ae941328180377d52d08e45",
            "656f7065a06b4ea682509f326b4d29db",
            "631a3cf92b17484c87a2851be36619d3",
            "eafb37e5505f41a8bce62272d5ba0df7",
            "ca7bef63244d483f8f324a676a09be5c"
          ]
        },
        "id": "bkEQwKOUYgXb",
        "outputId": "be709a9c-5cae-482a-c319-1d29f2663f67"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Epoch 1/5:   0%|          | 0/51 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cb5288d54d8245ca8230cf9fa0a4e2b3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Processing slices:   0%|          | 0/75 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ede1a600711c4f3bbc930e035249b57e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "outputs shape: torch.Size([1, 3, 512, 512])\n",
            "mask_slice_argmax shape: torch.Size([1, 512, 512])\n",
            "mask_slice_argmax unique value: tensor([0])\n",
            "outputs shape: torch.Size([1, 3, 512, 512])\n",
            "mask_slice_argmax shape: torch.Size([1, 512, 512])\n",
            "mask_slice_argmax unique value: tensor([0])\n",
            "outputs shape: torch.Size([1, 3, 512, 512])\n",
            "mask_slice_argmax shape: torch.Size([1, 512, 512])\n",
            "mask_slice_argmax unique value: tensor([0])\n",
            "outputs shape: torch.Size([1, 3, 512, 512])\n",
            "mask_slice_argmax shape: torch.Size([1, 512, 512])\n",
            "mask_slice_argmax unique value: tensor([0])\n",
            "outputs shape: torch.Size([1, 3, 512, 512])\n",
            "mask_slice_argmax shape: torch.Size([1, 512, 512])\n",
            "mask_slice_argmax unique value: tensor([0])\n",
            "outputs shape: torch.Size([1, 3, 512, 512])\n",
            "mask_slice_argmax shape: torch.Size([1, 512, 512])\n",
            "mask_slice_argmax unique value: tensor([0])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception ignored in: <function _xla_gc_callback at 0x7b2bd16c85e0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/jax/_src/lib/__init__.py\", line 97, in _xla_gc_callback\n",
            "    def _xla_gc_callback(*args):\n",
            "KeyboardInterrupt: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "outputs shape: torch.Size([1, 3, 512, 512])\n",
            "mask_slice_argmax shape: torch.Size([1, 512, 512])\n",
            "mask_slice_argmax unique value: tensor([0])\n",
            "outputs shape: torch.Size([1, 3, 512, 512])\n",
            "mask_slice_argmax shape: torch.Size([1, 512, 512])\n",
            "mask_slice_argmax unique value: tensor([0])\n",
            "outputs shape: torch.Size([1, 3, 512, 512])\n",
            "mask_slice_argmax shape: torch.Size([1, 512, 512])\n",
            "mask_slice_argmax unique value: tensor([0])\n",
            "outputs shape: torch.Size([1, 3, 512, 512])\n",
            "mask_slice_argmax shape: torch.Size([1, 512, 512])\n",
            "mask_slice_argmax unique value: tensor([0])\n",
            "outputs shape: torch.Size([1, 3, 512, 512])\n",
            "mask_slice_argmax shape: torch.Size([1, 512, 512])\n",
            "mask_slice_argmax unique value: tensor([0])\n",
            "outputs shape: torch.Size([1, 3, 512, 512])\n",
            "mask_slice_argmax shape: torch.Size([1, 512, 512])\n",
            "mask_slice_argmax unique value: tensor([0])\n",
            "outputs shape: torch.Size([1, 3, 512, 512])\n",
            "mask_slice_argmax shape: torch.Size([1, 512, 512])\n",
            "mask_slice_argmax unique value: tensor([0])\n",
            "outputs shape: torch.Size([1, 3, 512, 512])\n",
            "mask_slice_argmax shape: torch.Size([1, 512, 512])\n",
            "mask_slice_argmax unique value: tensor([0])\n",
            "outputs shape: torch.Size([1, 3, 512, 512])\n",
            "mask_slice_argmax shape: torch.Size([1, 512, 512])\n",
            "mask_slice_argmax unique value: tensor([0])\n",
            "outputs shape: torch.Size([1, 3, 512, 512])\n",
            "mask_slice_argmax shape: torch.Size([1, 512, 512])\n",
            "mask_slice_argmax unique value: tensor([0])\n",
            "outputs shape: torch.Size([1, 3, 512, 512])\n",
            "mask_slice_argmax shape: torch.Size([1, 512, 512])\n",
            "mask_slice_argmax unique value: tensor([0])\n",
            "outputs shape: torch.Size([1, 3, 512, 512])\n",
            "mask_slice_argmax shape: torch.Size([1, 512, 512])\n",
            "mask_slice_argmax unique value: tensor([0])\n",
            "outputs shape: torch.Size([1, 3, 512, 512])\n",
            "mask_slice_argmax shape: torch.Size([1, 512, 512])\n",
            "mask_slice_argmax unique value: tensor([0])\n",
            "outputs shape: torch.Size([1, 3, 512, 512])\n",
            "mask_slice_argmax shape: torch.Size([1, 512, 512])\n",
            "mask_slice_argmax unique value: tensor([0])\n",
            "outputs shape: torch.Size([1, 3, 512, 512])\n",
            "mask_slice_argmax shape: torch.Size([1, 512, 512])\n",
            "mask_slice_argmax unique value: tensor([0])\n",
            "outputs shape: torch.Size([1, 3, 512, 512])\n",
            "mask_slice_argmax shape: torch.Size([1, 512, 512])\n",
            "mask_slice_argmax unique value: tensor([0])\n",
            "outputs shape: torch.Size([1, 3, 512, 512])\n",
            "mask_slice_argmax shape: torch.Size([1, 512, 512])\n",
            "mask_slice_argmax unique value: tensor([0])\n",
            "outputs shape: torch.Size([1, 3, 512, 512])\n",
            "mask_slice_argmax shape: torch.Size([1, 512, 512])\n",
            "mask_slice_argmax unique value: tensor([0])\n",
            "outputs shape: torch.Size([1, 3, 512, 512])\n",
            "mask_slice_argmax shape: torch.Size([1, 512, 512])\n",
            "mask_slice_argmax unique value: tensor([0])\n",
            "outputs shape: torch.Size([1, 3, 512, 512])\n",
            "mask_slice_argmax shape: torch.Size([1, 512, 512])\n",
            "mask_slice_argmax unique value: tensor([0])\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-993e47c90319>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m                     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvolume_slice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'outputs shape: {outputs.shape}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m                     \u001b[0mmask_slice_argmax\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask_slice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/segmentation_models_pytorch/base/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_input_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0mdecoder_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/segmentation_models_pytorch/encoders/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_depth\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m             \u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownsample\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             \u001b[0midentity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownsample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0midentity\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 460\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    454\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m--> 456\u001b[0;31m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0m\u001b[1;32m    457\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from tqdm import tqdm\n",
        "\n",
        "# # 模拟训练过程\n",
        "# for volume_slices, mask_slices in tqdm(data_loader, desc='Training'):\n",
        "#     D = volume_slices.shape[-1]  # 获取切片数量\n",
        "#     total_loss = 0.0  # 初始化累计损失\n",
        "\n",
        "#     for d in tqdm(range(D)):\n",
        "#         volume_slice = volume_slices[:, :, :, d].unsqueeze(1).to(device)\n",
        "#         mask_slice = mask_slices[:, :, :, :, d].to(device)\n",
        "#         # print(volume_slice.shape, mask_slice.shape)\n",
        "\n",
        "#         optimizer.zero_grad()\n",
        "\n",
        "#         outputs = model(volume_slice)\n",
        "\n",
        "#         # 将掩膜转换为类别索引形式 (B, H, W)\n",
        "#         mask_slice = torch.argmax(mask_slice, 1)  # 在类别维度上使用argmax\n",
        "\n",
        "#         loss = criterion(outputs, mask_slice.long())\n",
        "#         loss.backward()\n",
        "#         optimizer.step()\n",
        "\n",
        "#         total_loss += loss.item()\n",
        "#         # tqdm.write(f'Loss: {loss.item():.4f}')\n",
        "\n",
        "#     # 计算并显示当前批次的平均损失\n",
        "#     avg_loss = total_loss / D\n",
        "#     tqdm.write(f'Average loss: {avg_loss:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 512
        },
        "id": "Ljj3dcsry-dA",
        "outputId": "5de56685-d3cf-4074-90a1-ff2014bf3fc1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   0%|          | 0/51 [00:00<?, ?it/s]\n",
            "  0%|          | 0/75 [00:00<?, ?it/s]\u001b[A\n",
            "  1%|▏         | 1/75 [00:03<04:39,  3.78s/it]\u001b[A\n",
            "  3%|▎         | 2/75 [00:07<04:13,  3.48s/it]\u001b[A\n",
            "  4%|▍         | 3/75 [00:09<03:21,  2.80s/it]\u001b[A\n",
            "  5%|▌         | 4/75 [00:10<02:53,  2.45s/it]\u001b[A\n",
            "  7%|▋         | 5/75 [00:13<02:41,  2.31s/it]\u001b[A\n",
            "  8%|▊         | 6/75 [00:15<02:58,  2.58s/it]\n",
            "Training:   0%|          | 0/51 [00:19<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-088b770e0508>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvolume_slice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;31m# 将掩膜转换为类别索引形式 (B, H, W)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/segmentation_models_pytorch/base/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mdecoder_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mmasks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msegmentation_head\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/segmentation_models_pytorch/decoders/unet/decoder.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *features)\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_block\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[0mskip\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mskips\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mskips\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/segmentation_models_pytorch/decoders/unet/decoder.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, skip)\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0mused\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mnormalization\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0;32min\u001b[0m \u001b[0meval\u001b[0m \u001b[0mmode\u001b[0m \u001b[0mwhen\u001b[0m \u001b[0mbuffers\u001b[0m \u001b[0mare\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \"\"\"\n\u001b[0;32m--> 175\u001b[0;31m         return F.batch_norm(\n\u001b[0m\u001b[1;32m    176\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m             \u001b[0;31m# If buffers are not to be tracked, ensure that they won't be updated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   2480\u001b[0m         \u001b[0m_verify_batch_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2481\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2482\u001b[0;31m     return torch.batch_norm(\n\u001b[0m\u001b[1;32m   2483\u001b[0m         \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2484\u001b[0m     )\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **We've got data, so next step is to preprocess🍖**\n",
        "1. Get the fucking slices\n",
        "2. Convert them tensors\n",
        "2. Maybe some resize?\n",
        "3. Windowed to the volume slices"
      ],
      "metadata": {
        "id": "-DMFzFH4nTlT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "volume_list, segmentation_list"
      ],
      "metadata": {
        "id": "RJTpx7C1hd9C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_volume = read_nii(volume_list[0])\n",
        "test_volume.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jrPtPimTp6Dq",
        "outputId": "156fd6c9-275f-43b3-ad5e-351640559200"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(512, 512, 75)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gbP6UK1tdpkL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Get into the dataloader part (everytime really stressing me out🤬)**"
      ],
      "metadata": {
        "id": "Gs7TtDj6ljrc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nibabel as nib\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from random import randint\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "dicom_windows = types.SimpleNamespace( # some tuples to store\n",
        "    brain=(80,40),\n",
        "    subdural=(254,100),\n",
        "    stroke=(8,32),\n",
        "    brain_bone=(2800,600),\n",
        "    brain_soft=(375,40),\n",
        "    lungs=(1500,-600),\n",
        "    mediastinum=(350,50),\n",
        "    abdomen_soft=(400,50),\n",
        "    liver=(400,100),\n",
        "    spine_soft=(250,50),\n",
        "    spine_bone=(1800,400),\n",
        "    custom = (200,60)\n",
        ")\n",
        "\n",
        "\n",
        "def read_nii(filepath, interval=3):\n",
        "    '''\n",
        "    Reads .nii file and returns selected slices as a NumPy array.\n",
        "    '''\n",
        "    ct_scan = nib.load(filepath)\n",
        "    array = ct_scan.get_fdata()\n",
        "    selected_slices = array[:,:,::interval]  # Assuming the slicing dimension is the last one\n",
        "    selected_slices = np.rot90(np.array(selected_slices))\n",
        "    return selected_slices.copy()\n",
        "\n",
        "class NiiDataset(Dataset):\n",
        "    def __init__(self, volume_list, segmentation_list, transform=None):\n",
        "        self.volume_list = volume_list\n",
        "        self.segmentation_list = segmentation_list\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.volume_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        volume_path = self.volume_list[idx]\n",
        "        segmentation_path = self.segmentation_list[idx]\n",
        "\n",
        "        volume_slices = read_nii(volume_path)\n",
        "        segmentation_slices = read_nii(segmentation_path)\n",
        "\n",
        "        # Convert slices to tensors\n",
        "        volume_slices = tensor(volume_slices.astype(np.float32)).windowed(*dicom_windows.liver)\n",
        "        segmentation_slices = tensor(segmentation_slices.astype(np.int64))\n",
        "\n",
        "        # Handle segmentation (optional, depending on your model's needs)\n",
        "        # One-hot encoding\n",
        "        segmentation_slices = F.one_hot(segmentation_slices, num_classes=3)  # 3 classes in your case\n",
        "        segmentation_slices = segmentation_slices.permute(3, 0, 1, 2).contiguous()\n",
        "        # Resulting shape: [slices, channels, height, width]\n",
        "\n",
        "        # Align slices (if necessary, this step can include preprocessing such as normalization)\n",
        "\n",
        "        if self.transform:\n",
        "            volume_slices = self.transform(volume_slices)\n",
        "            segmentation_slices = self.transform(segmentation_slices)\n",
        "\n",
        "\n",
        "\n",
        "        return volume_slices, segmentation_slices\n"
      ],
      "metadata": {
        "id": "IyFMLT9blcLJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = NiiDataset(volume_list, segmentation_list)\n",
        "testData = DataLoader(dataset, batch_size=1, shuffle=False)\n",
        "for volume, segmentation in dataset:\n",
        "    volume_shape = volume.shape\n",
        "    segmentation_shape = segmentation.shape\n",
        "\n",
        "    index = segmentation.shape[-1] // 2  # Get the middle slice index\n",
        "    volume_slice = volume[:, :, index].numpy()  # Convert to NumPy array and select first slice\n",
        "    volume_slice_shape = volume_slice.shape\n",
        "    segmentation_slice = segmentation[:, :, :, index].numpy()  # Convert to NumPy array and select first slice\n",
        "    segmentation_slice_shape = segmentation_slice.shape\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    print(f\"Volume Shape:        {volume_shape}\")\n",
        "    print(f\"Volume Slice Shape:     {volume_slice_shape}\")\n",
        "    print(f\"Segmentation Shape:  {segmentation_shape}\")\n",
        "    print(f\"Segmentation Slice Shape: {segmentation_slice.shape}\")\n",
        "    print(f\"Volume Data Type:    {volume.dtype}\")\n",
        "    print(f\"Segmentation Type:   {segmentation.dtype}\")\n",
        "    print(f\"Volume Type:         {volume.type()}\")\n",
        "    print(f\"Segmentation Type:   {segmentation.type()}\")\n",
        "    print(f\"Volume Min/Max:      {volume.min()}/{volume.max()}\")\n",
        "    print(f\"Segmentation Min/Max: {segmentation.min()}/{segmentation.max()}\")\n",
        "    print(f\"Segmentation Unique: {segmentation.unique()}\")\n",
        "\n",
        "    fig, ax = plt.subplots(1, 4, figsize=(20, 5))\n",
        "\n",
        "    ax[0].imshow(volume_slice)\n",
        "    ax[0].set_title('Volume Slice')\n",
        "    ax[0].axis('off')  # Turn off axis\n",
        "\n",
        "    ax[1].imshow(segmentation_slice[0])\n",
        "    ax[1].set_title('Background')\n",
        "    ax[1].axis('off')  # Turn off axis\n",
        "\n",
        "    ax[2].imshow(segmentation_slice[1])\n",
        "    ax[2].set_title('Liver')\n",
        "    ax[2].axis('off')  # Turn off axis\n",
        "\n",
        "    ax[3].imshow(segmentation_slice[2])\n",
        "    ax[3].set_title('Tumor')\n",
        "    ax[3].axis('off')  # Turn off axis\n",
        "\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "Oco0TLKflceX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **MODEL setup🥲**"
      ],
      "metadata": {
        "id": "QqayeFYoxuEn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Finally the training loop🥱**"
      ],
      "metadata": {
        "id": "PcoNtxpi5b76"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install segmentation_models_pytorch\n",
        "# import segmentation_models_pytorch as smp"
      ],
      "metadata": {
        "id": "WqZ9gHUD7Qpu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}